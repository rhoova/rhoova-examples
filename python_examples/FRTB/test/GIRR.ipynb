{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a4fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Constants import *\n",
    "from positions import loadpositions\n",
    "from rhoova_func import *\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c1c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks=loadpositions()\n",
    "tasks=tasks[:2]\n",
    "#tasks[0][\"notional\"]=2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c70162f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_id</th>\n",
       "      <th>settlementDate</th>\n",
       "      <th>notional</th>\n",
       "      <th>currency</th>\n",
       "      <th>buySell</th>\n",
       "      <th>calculation_type</th>\n",
       "      <th>discountCurve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRB1001</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>1000000</td>\n",
       "      <td>TRY</td>\n",
       "      <td>Buy</td>\n",
       "      <td>fixed_rate_bond</td>\n",
       "      <td>TRY_IRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRN1001</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>Buy</td>\n",
       "      <td>floating_rate_bond</td>\n",
       "      <td>USD_IRS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trade_id settlementDate  notional currency buySell    calculation_type  \\\n",
       "0  FRB1001     2021-02-01   1000000      TRY     Buy     fixed_rate_bond   \n",
       "1  FRN1001     2021-02-01    150000      USD     Buy  floating_rate_bond   \n",
       "\n",
       "  discountCurve  \n",
       "0       TRY_IRS  \n",
       "1       USD_IRS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_df = pd.json_normalize(tasks, sep='_')\n",
    "tasks_df['currency'] = tasks_df[['fixedRateBondDefinition_currency', 'floatingBondDefinition_currency']].bfill(axis=1).iloc[:, 0]\n",
    "tasks_df.drop(columns=['fixedRateBondDefinition_currency', 'floatingBondDefinition_currency'], inplace=True)\n",
    "columns=['trade_id', 'settlementDate', 'notional','currency', 'buySell', 'calculation_type','discountCurve']\n",
    "tasks_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbe1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "riskdata = {\n",
    "  \"id\": \"PORTFOLIO1\",\n",
    "  \"name\": \"PORTFOLIO 1\",\n",
    "  \"method\": \"VaR\",\n",
    "  \"valuationDate\": \"2021-01-28\",\n",
    "  \"valuationCurrency\": \"TRY\",\n",
    "  \"riskMethod\": \"DELTANORMAL\",\n",
    "  \"horizon\": 252,\n",
    "  \"confidenceInterval\": 0.99,\n",
    "  \"returnType\": \"NONE\",\n",
    "  \"trend\": False,\n",
    "  \"calendar\": \"Turkey\",\n",
    "  \"timeBucket\": [\"0D\",\"1D\",\"1W\",\"2W\",\"3W\",\"1M\",\"2M\",\"3M\",\"6M\",\"9M\",\"1Y\",\"2Y\",\"3Y\",\"4Y\",\n",
    "                \"5Y\",\"6Y\",\"7Y\",\"8Y\",\"9Y\",\"10Y\",\"12Y\",\"15Y\",\"20Y\",\"25Y\",\"30Y\",\"40Y\",\"50Y\"],\n",
    "  \"fillNa\": \"BACKWARD\",\n",
    "  \"maxFillNaDays\": 5,\n",
    "  \"tasks\": tasks,\n",
    "  \"curves\": [TRY_IRS,USD_IRS],\n",
    "  \"yieldData\": yielddata.to_dict('records'),\n",
    "  \"marketData\":marketdata.to_dict('records'),\n",
    "  \"volatilityData\":voldata.to_dict('records'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8b4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=get_result(riskdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77d7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivities(data):\n",
    "    bp=1/10000\n",
    "    data['sensitivity'] =data['cashflow'] * (pow((1+data['rate']-bp),-1*data['timeToMatByYear'])-pow((1+data['rate']),-1*data['timeToMatByYear']))/bp\n",
    "    return  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80be78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_volatility(sensitivity,result):\n",
    "    riskfactor_vol=pd.DataFrame(pd.DataFrame(result.get(\"deltaRiskFactors\")).T.std())\n",
    "    riskfactor_vol.columns=[\"volatility\"]\n",
    "    sensitivity=sensitivity.set_index(\"bin\")\n",
    "    tmp_df=pd.merge(sensitivity,riskfactor_vol,left_index=True, right_index=True)\n",
    "    tmp_df[\"weighted_sensitivities\"]=tmp_df[\"sensitivity\"]*tmp_df[\"volatility\"]*tmp_df[\"rate\"]\n",
    "    return tmp_df[[\"weighted_sensitivities\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf9e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulatory_rw={\"TRY_IRS0D\":0.000065,\"TRY_IRS1D\":0.000065,\"TRY_IRS1W\":0.000065,\"TRY_IRS2W\":0.000065,\n",
    "               \"TRY_IRS3W\":0.000065,\"TRY_IRS1M\":0.000065,\"TRY_IRS2M\":0.000082,\"TRY_IRS3M\":0.000097,\n",
    "               \"TRY_IRS6M\":0.000079,\"TRY_IRS9M\":0.000079,\"TRY_IRS1Y\":0.000091,\"TRY_IRS2Y\":0.000103,\n",
    "               \"TRY_IRS3Y\":0.000148,\"TRY_IRS4Y\":0.000248,\"TRY_IRS5Y\":0.000314,\"TRY_IRS6Y\":0.000425,\n",
    "               \"TRY_IRS7Y\":0.000486,\"TRY_IRS8Y\":0.000565,\"TRY_IRS9Y\":0.000619,\"TRY_IRS10Y\":0.000612,\n",
    "               \"TRY_IRS12Y\":0.000701,\"TRY_IRS15Y\":0.000795,\"TRY_IRS20Y\":0.000879,\"TRY_IRS25Y\":0.000922,\n",
    "               \"TRY_IRS30Y\":0.000891,\"TRY_IRS40Y\":0.001186,\"TRY_IRS50Y\":0.001499}\n",
    "rw=pd.DataFrame([regulatory_rw]).T\n",
    "rw.columns=[\"RW\"]\n",
    "def map_rw(sensitivity,rw):\n",
    "    sensitivity=sensitivity.set_index(\"bin\")\n",
    "    tmp_df=pd.merge(sensitivity,rw,left_index=True, right_index=True)\n",
    "    tmp_df[\"weighted_sensitivities\"]=tmp_df[\"sensitivity\"]*tmp_df[\"RW\"]\n",
    "    return tmp_df[[\"weighted_sensitivities\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcca10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "As we have the bucket level capital charge \n",
    "now we move to interbucket capital charge\n",
    "in our case we have two buckets(TRY,USD)\n",
    "final capital charge is the maximum of three gamma scenarios\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def calculate_capital_charge(K: np.ndarray, gamma: np.ndarray, S: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the capital based on given parameters.\n",
    "    \n",
    "    Args:\n",
    "        K (np.ndarray): Array of K values per currency.\n",
    "        gamma (np.ndarray): Correlation matrix for risk factors.\n",
    "        S (np.ndarray): Sensitivities per currency.\n",
    "    \n",
    "    Returns:\n",
    "        float: Computed risk capital value.\n",
    "    \"\"\"\n",
    "    term1 = np.sum(K ** 2)\n",
    "    term2 = np.sum(np.triu(gamma * np.outer(S, S), k=1))\n",
    "    return np.sqrt(term1 + 2 * term2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134480d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gamma_matrix(size: int, coeff: float) -> np.ndarray:\n",
    "    \"\"\"Generates a gamma correlation matrix of given size.\"\"\"\n",
    "    gamma = np.full((size, size), coeff)\n",
    "    np.fill_diagonal(gamma, 1.0)\n",
    "    return gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57eee33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_corr=pd.DataFrame(result.get(\"riskFactorsCorr\"))\n",
    "all_ir_riskfactor=list(result.get(\"forDV01\").keys())\n",
    "all_currencies= [rf.split(\"_\")[0] for rf in all_ir_riskfactor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac610585",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ir_riskfactor_lst=[]\n",
    "for rf in all_ir_riskfactor:\n",
    "    rf_bucket=pd.DataFrame(result.get(\"forDV01\").get(rf))\n",
    "    rf_bucket[\"currency\"]=rf_bucket[\"bin\"].apply(lambda x: x.split('_')[0])\n",
    "    all_ir_riskfactor_lst.append(rf_bucket)\n",
    "all_ir_riskfactor_df=pd.concat(all_ir_riskfactor_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6614f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kb_matrix_dict={}\n",
    "Sb_dict={}\n",
    "for curr in all_currencies:\n",
    "    correlation_scenario={}\n",
    "    rf_bucket=all_ir_riskfactor_df[all_ir_riskfactor_df[\"currency\"]==curr]\n",
    "    rf_sensitivities=sensitivities(rf_bucket)\n",
    "    weighted_sensitivities =map_volatility(rf_sensitivities,result)\n",
    "    #reg_weighted_sensitivities=map_rw(rf_sensitivities,rw)\n",
    "    rf_corr_tmp=rf_corr[list(rf_bucket[\"bin\"])]\n",
    "    rf_corr_tmp=rf_corr_tmp[rf_corr_tmp.index.isin(list(rf_bucket[\"bin\"]))]\n",
    "    ## Correlation Scenarios\n",
    "    Base_scenario = rf_corr_tmp.applymap(lambda x : x*1)\n",
    "    High_scenario = rf_corr_tmp.applymap(lambda x : min(x*1.25,1))\n",
    "    Low_scenario = rf_corr_tmp.applymap(lambda x : max(x*2 - 1 , 0.75 * x))\n",
    "    Kb_base = np.sqrt(weighted_sensitivities.T@Base_scenario@weighted_sensitivities)\n",
    "    Kb_low = np.sqrt(weighted_sensitivities.T@Low_scenario@weighted_sensitivities)\n",
    "    Kb_high = np.sqrt(weighted_sensitivities.T@High_scenario@weighted_sensitivities)\n",
    "    #Kb_matrix = np.array([Kb_base, Kb_low, Kb_high])\n",
    "    correlation_scenario[\"base\"]= np.array(Kb_base)\n",
    "    correlation_scenario[\"low\"]=np.array(Kb_low)\n",
    "    correlation_scenario[\"high\"]=np.array(Kb_high)\n",
    "    Kb_matrix_dict[curr]=correlation_scenario\n",
    "    Sb_dict[curr] = list(weighted_sensitivities.sum())[0] # this is used in interbucket aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456354fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: Base, Capital Charge: 2235.707823491689\n",
      "Gamma: Low, Capital Charge: 2196.2070429620458\n",
      "Gamma: High, Capital Charge: 2274.5227122382826\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "K_values =Kb_matrix_dict\n",
    "S_values= Sb_dict\n",
    "gamma_coefficients = {\"base\": 0.5, \"low\": 0.375, \"high\": 0.625}\n",
    "\n",
    "# Extracting K arrays\n",
    "currencies = list(K_values.keys())\n",
    "num_currencies = len(currencies)\n",
    "\n",
    "K_base = np.array([K_values[currency]['base'][0][0] for currency in currencies])\n",
    "K_low = np.array([K_values[currency]['low'][0][0] for currency in currencies])\n",
    "K_high = np.array([K_values[currency]['high'][0][0] for currency in currencies])\n",
    "\n",
    "S = np.array([S_values[currency] for currency in currencies])\n",
    "\n",
    "# Gamma coefficients\n",
    "\n",
    "gamma_base = create_gamma_matrix(num_currencies, gamma_coefficients[\"base\"])\n",
    "gamma_low = create_gamma_matrix(num_currencies, gamma_coefficients[\"low\"])\n",
    "gamma_high = create_gamma_matrix(num_currencies, gamma_coefficients[\"high\"])\n",
    "\n",
    "\n",
    "# Calculate capital charges values\n",
    "RC_base = calculate_capital_charge(K_base, gamma_base, S)\n",
    "RC_low = calculate_capital_charge(K_low, gamma_low, S)\n",
    "RC_high = calculate_capital_charge(K_high, gamma_high, S)\n",
    "\n",
    "print(f\"Gamma: Base, Capital Charge: {RC_base}\")\n",
    "print(f\"Gamma: Low, Capital Charge: {RC_low}\")\n",
    "print(f\"Gamma: High, Capital Charge: {RC_high}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178e1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
